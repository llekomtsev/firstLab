### Отчет по первой лабораторной работе

---

## **1. Теоретическая база**

### **Цель работы**  
Разработать и реализовать архитектуру нейронной сети на основе **SqueezeNet** для задачи классификации изображений автомобилей из набора данных. Провести сравнение двух методов оптимизации: классического **Adam** и его варианта **AmsGrad**, оценив их влияние на точность модели и скорость сходимости.

### **Описание SqueezeNet**  
SqueezeNet — компактная сверточная нейронная сеть (CNN), которая достигает высокой точности классификации при минимальном количестве параметров. Основные компоненты:
- **Fire-модули:** содержат слои "squeeze" (1x1 свертки) и "expand" (1x1 и 3x3 свертки).
- **Уменьшение количества параметров:** замена сверток 3x3 на 1x1.
- **Позднее объединение:** Pooling слои перемещены ближе к выходу для сохранения информации.
- **Сжатие параметров:** достигается за счет агрессивной параметрической регуляризации.

### **Описание оптимизаторов**

#### **Adam**  
Adam (Adaptive Moment Estimation) адаптирует скорость обучения для каждого параметра на основе скользящих средних значений градиентов и их квадратов:
- Обновление скользящих средних градиента \( m_t \) и квадратов градиента \( v_t \):
  ```math
  m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
  v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
  ```
- Корректировка смещений:
  ```math
  \hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
  ```
- Обновление параметров:
  ```math
  \theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
  ```

#### **AmsGrad**  
AmsGrad модифицирует Adam, чтобы избежать проблем с медленной сходимостью, используя максимальное значение исторических градиентов:
```math
\hat{v}_t = \max(\hat{v}_{t-1}, v_t)
\theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
```

---

## **2. Разработанная система**

### **Архитектура и принципы работы нейронной сети**  
Архитектура модели основана на SqueezeNet, состоящей из последовательности Fire-модулей и пулинговых слоев. SqueezeNet минимизирует количество параметров, что делает её пригодной для работы на устройствах с ограниченными вычислительными ресурсами.

#### **Основные компоненты:**
1. **Fire-модуль:**  
   Fire-модуль является ключевой частью архитектуры SqueezeNet и состоит из двух компонентов:
   - **Squeeze:** сверточный слой с ядром \(1 \times 1\), который уменьшает количество каналов.
   - **Expand:** комбинация сверток \(1 \times 1\) и \(3 \times 3\) для увеличения количества каналов и извлечения пространственных признаков.
  
2. **Слои пулинга:**  
   MaxPooling слои используются для снижения размерности признаков и увеличения вычислительной эффективности.

3. **Полносвязный классификатор:**  
   Последний слой сети преобразует выходы сверточных блоков в вероятности классов.
   
5. **Сверточные слои:** извлечение признаков изображений.  

### **Алгоритмы и принципы работы**  
#### **Обучение модели:**  
1. **Функция потерь:**  
   - Используется стандартная функция потерь **CrossEntropyLoss**, которая хорошо подходит для задач классификации.

2. **Оптимизаторы:**  
   - **Adam:** классический оптимизатор, эффективно работающий с большими объемами данных и обеспечивающий быструю сходимость, реализован через `torch.optim.Adam`.
   - **AmsGrad:** модификация Adam, которая предотвращает накопление ошибки в моментной оценке градиентов, улучшая устойчивость к локальным минимумам, настройка через параметр `amsgrad=True`.

3. **Метрики:**  
   - Потери на обучающей и тестовой выборках.
   - Точность предсказаний на тестовом наборе данных.

### **Подготовка данных**  
1. **Извлечение данных:**  
   Данные загружаются из файла `cars_annos.mat` и разделяются на тренировочные и тестовые изображения.  
   
2. **Предобработка изображений:**  
   - Масштабирование изображений до \(224 \times 224\) пикселей.
   - Преобразование в тензоры и нормализация по средним и стандартным отклонениям.
- Используемые преобразования:
  - `Resize`
  - `ToTensor`
  - `Normalize`

3. **Аугментация данных:**  
   Включает случайные горизонтальные перевороты и изменения яркости для повышения обобщающей способности модели.

### **Технические параметры**  
- **Платформа:** PyTorch
- **Устройство:** CPU (Intel UHD Graphics)
- **Размер батча:** 64
- **Число эпох:** 10
- **Начальная скорость обучения:** 0.0001
- **Регуляризация:** Dropout 0.5 перед выходным слоем

### **Особенности реализации и ограничения**
- Использование CPU увеличивает время обучения по сравнению с GPU.
- Из-за ограниченного вычислительного ресурса размер сети и параметры были уменьшены для обеспечения приемлемой производительности.


---

## **3. Результаты выполнения программы**

### **Обучение с Adam**
**Тестовая точность:** 37.77%

![Снимок экрана 2025-01-13 004327](https://github.com/user-attachments/assets/5639cf30-ee30-446f-9937-4adf753a03d6)
![Снимок экрана 2025-01-13 004337](https://github.com/user-attachments/assets/3a909af0-b9a3-4693-a973-b7e14caaee1e)

### **Обучение с AmsGrad**
**Тестовая точность:** 54.20%

![Снимок экрана 2025-01-13 004346](https://github.com/user-attachments/assets/7762eec1-d01a-4cb3-8a3a-78f9c6634a1c)


---

## **4. Анализ результатов**
- **Сходимость:** AmsGrad показал более стабильное обновление градиентов и устойчивость к локальным минимумам.
- **Точность:** Adam на начальных этапах сходился быстрее, но AmsGrad обеспечил лучшую стабильность.
- **Время:** Adam оказался быстрее благодаря меньшему числу вычислений.

---

## **5. Использованные источники**
1. SqueezeNet: https://arxiv.org/abs/1602.07360  
2. AmsGrad Optimization: https://openreview.net/pdf?id=ryQu7f-RZ  
3. Cars Dataset: https://disk.yandex.ru/d/yjoM_PpZTqm0bA  
4. PyTorch Documentation: https://pytorch.org/docs/stable
