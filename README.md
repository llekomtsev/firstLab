# **Отчет по первой лабораторной работе**

## **1. Теоретическая база**

### **Цель работы**  
Разработать и реализовать архитектуру нейронной сети на основе **SqueezeNet** для задачи классификации изображений автомобилей из набора данных. Провести сравнение двух методов оптимизации: классического **Adam** и его варианта **AmsGrad**, оценив их влияние на точность модели и скорость сходимости.

### **Описание SqueezeNet**  
SqueezeNet — компактная сверточная нейронная сеть (CNN), которая достигает высокой точности классификации при минимальном количестве параметров. Основные компоненты:
- **Fire-модули:** содержат слои "squeeze" (1x1 свертки) и "expand" (1x1 и 3x3 свертки).
- **Уменьшение количества параметров:** замена сверток 3x3 на 1x1.
- **Позднее объединение:** Pooling слои перемещены ближе к выходу для сохранения информации.
- **Сжатие параметров:** достигается за счет агрессивной параметрической регуляризации.

### **Описание оптимизаторов**

#### **Adam**  
Adam (Adaptive Moment Estimation) адаптирует скорость обучения для каждого параметра на основе скользящих средних значений градиентов и их квадратов:

1. Обновление скользящих средних градиента $m_t$ и квадратов градиента $v_t$:
   
 ```math
   m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
 ```

  ```math
   v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
   ```
   где:
   - $m_t$ — скользящее среднее градиента на шаге $t$,
   - $v_t$ — скользящее среднее квадратов градиента на шаге $t$,
   - $\beta_1$ — коэффициент сглаживания для первого момента (обычно $0.9$),
   - $\beta_2$ — коэффициент сглаживания для второго момента (обычно $0.999$),
   - $g_t$ — градиент функции потерь на шаге $t$.

2. Корректировка смещений:

   $$\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}$$
   
   

4. Обновление параметров:
   
   
   $$\theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$
   
   где:
   - $\theta_t$ — параметры модели на шаге $t$,
   - $\eta$ — скорость обучения,
   - $\epsilon$ — малое значение для предотвращения деления на ноль (обычно $10^{-8}$).

#### **AmsGrad**  
AmsGrad модифицирует Adam, чтобы избежать проблем с медленной сходимостью, используя максимальное значение исторических градиентов:

```math
\hat{v}_t = \max(\hat{v}_{t-1}, v_t)
```
```math
\theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
```


где:
- $\hat{v}_t$ — максимальное значение исторических скользящих средних квадратов градиентов на шаге $t$,
- $\hat{v}_{t-1}$ — максимальное значение исторических квадратов градиентов на предыдущем шаге $t-1$.

---

## **2. Разработанная система**

### **Архитектура и принципы работы нейронной сети**  
Архитектура модели основана на SqueezeNet, состоящей из последовательности Fire-модулей и пулинговых слоев. SqueezeNet минимизирует количество параметров, что делает её пригодной для работы на устройствах с ограниченными вычислительными ресурсами.

#### **Основные компоненты**
1. **Fire-модуль:**  
   Fire-модуль состоит из двух компонентов:
   - **Squeeze:** сверточный слой с ядром $1 \times 1$, который уменьшает количество каналов.
   - **Expand:** комбинация сверток $1 \times 1$ и $3 \times 3$ для увеличения количества каналов и извлечения пространственных признаков.
  
2. **Слои пулинга:**  
   MaxPooling слои используются для снижения размерности признаков и увеличения вычислительной эффективности.

3. **Полносвязный классификатор:**  
   Последний слой сети преобразует выходы сверточных блоков в вероятности классов.

### **Алгоритмы и принципы работы**

#### **Обучение модели**
1. **Функция потерь:**  
   Используется стандартная функция потерь **CrossEntropyLoss**, подходящая для задачи классификации:
   
   $$L = - \sum_{i=1}^{N} \sum_{j=1}^{C} y_{ij} \log(\hat{y}_{ij})$$
   
   где:
   - $N$ — количество объектов,  
   - $C$ — количество классов,  
   - $y_{ij}$ — истинные метки классов,  
   - $\hat{y}_{ij}$ — предсказанные вероятности.

2. **Оптимизаторы:**  
   - **Adam:** реализован через `torch.optim.Adam`.
   - **AmsGrad:** настройка через параметр `amsgrad=True`.

3. **Метрики:**  
   - Потери на обучающей и тестовой выборках.
   - Точность предсказаний на тестовом наборе данных.

### **Подготовка данных**
1. **Извлечение данных:**  
   Данные загружаются из файла `cars_annos.mat` и разделяются на тренировочные и тестовые изображения.

2. **Предобработка изображений:**  
   - Масштабирование изображений до $224 \times 224$ пикселей.
   - Преобразование в тензоры и нормализация по средним и стандартным отклонениям.
   
   Используемые преобразования:
   - `Resize`
   - `ToTensor`
   - `Normalize`

3. **Аугментация данных:**  
   Включает случайные горизонтальные перевороты и изменения яркости.

### **Технические параметры**
- **Платформа:** PyTorch  
- **Устройство:** CPU (Intel UHD Graphics)  
- **Размер батча:** 64  
- **Число эпох:** 10  
- **Начальная скорость обучения:** 0.0001  
- **Регуляризация:** Dropout 0.5 перед выходным слоем

--- 
---
- Использование CPU увеличивает время обучения по сравнению с GPU.
- Из-за ограниченного вычислительного ресурса размер сети и параметры были уменьшены для обеспечения приемлемой производительности.
---

## **3. Результаты выполнения программы**

### **Обучение с Adam**
**Тестовая точность:** 37.77%

![Снимок экрана 2025-01-13 004327](https://github.com/user-attachments/assets/5639cf30-ee30-446f-9937-4adf753a03d6)
![Снимок экрана 2025-01-13 004337](https://github.com/user-attachments/assets/3a909af0-b9a3-4693-a973-b7e14caaee1e)

### **Обучение с AmsGrad**
**Тестовая точность:** 54.20%

![Снимок экрана 2025-01-13 004346](https://github.com/user-attachments/assets/7762eec1-d01a-4cb3-8a3a-78f9c6634a1c)


---

## **4. Анализ результатов**
- **Сходимость:** AmsGrad показал более стабильное обновление градиентов и устойчивость к локальным минимумам.
- **Точность:** Adam на начальных этапах сходился быстрее, но AmsGrad обеспечил лучшую стабильность.
- **Время:** Adam оказался быстрее благодаря меньшему числу вычислений.

---

## **5. Использованные источники**
1. SqueezeNet: https://arxiv.org/abs/1602.07360  
2. AmsGrad Optimization: https://openreview.net/pdf?id=ryQu7f-RZ  
3. Cars Dataset: https://disk.yandex.ru/d/yjoM_PpZTqm0bA  
4. PyTorch Documentation: https://pytorch.org/docs/stable
